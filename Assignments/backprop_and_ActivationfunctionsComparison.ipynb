{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq9fiwaot5z7",
        "colab_type": "text"
      },
      "source": [
        "#                      Backpropagation Learning Programming Assignment \n",
        "\n",
        "\n",
        "*   Write a program for the backpropagation algorithm.\n",
        "*   No. of layers, No. of neurons and type of output function, in each layer can\n",
        "be inputs.\n",
        "*   Demonstrating training and testing for task of your choice. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4k2MWWqK2bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPbJ8Ch0E6aL",
        "colab_type": "text"
      },
      "source": [
        "### Loading MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-WmP4pqE3Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, Y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "Y = np.array(list(map(int, Y)))\n",
        "\n",
        "one_idx = Y==1\n",
        "zero_idx = Y==0\n",
        "idx = np.logical_or(one_idx, zero_idx)\n",
        "# print(len(one_idx), len(zero_idx), len(idx))\n",
        "X = X[idx]\n",
        "Y = Y[idx]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvdnxDV6ODNq",
        "colab_type": "code",
        "outputId": "750e49fa-ca00-42f4-f96d-512593d89e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state=42)\n",
        "y_train = y_train.reshape((-1,1))\n",
        "y_test = y_test.reshape((-1,1))\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9902, 784) (9902, 1)\n",
            "(4878, 784) (4878, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dLmR9PjF3Rn",
        "colab_type": "code",
        "outputId": "fda36fa7-8643-40a5-9294-95e97aca493f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0].reshape((28,28)))\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiAJwg4kQdiBJAg7kARhB5Ig7EAS/w8U0hSxDFDT9gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHHk9_TOtk7N",
        "colab_type": "code",
        "outputId": "4f5ebaa4-a337-4fa2-f387-e1e9974ef5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "X_train = np.transpose(x_train/255)\n",
        "Y_train = np.transpose(y_train)\n",
        "X_test = np.transpose(x_test/255)\n",
        "Y_test = np.transpose(y_test)\n",
        "print (\"\\nTraining Input ->\") \n",
        "print(X_train.shape)\n",
        "print (\"\\nTraining Output ->\") \n",
        "print(Y_train.shape)\n",
        "print (\"\\nTesting Input ->\") \n",
        "print(X_test.shape)\n",
        "print (\"\\nTesting Output ->\") \n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Input ->\n",
            "(784, 9902)\n",
            "\n",
            "Training Output ->\n",
            "(1, 9902)\n",
            "\n",
            "Testing Input ->\n",
            "(784, 4878)\n",
            "\n",
            "Testing Output ->\n",
            "(1, 4878)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRHCmo3Wu_59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    cache = Z\n",
        "    \n",
        "    return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "    A = np.maximum(0,Z)\n",
        "    \n",
        "    assert(A.shape == Z.shape)\n",
        "    \n",
        "    cache = Z \n",
        "    return A, cache\n",
        "\n",
        "\n",
        "def relu_backward(dA, cache):\n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "    \n",
        "    # When z <= 0, you should set dz to 0 as well. \n",
        "    dZ[Z <= 0] = 0\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "  \n",
        "    Z = cache\n",
        "    \n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFyzFnyy-PyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) \n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwJCBsim-T4z",
        "colab_type": "code",
        "outputId": "d187ee2a-cb8f-4386-c69b-09a8ba94e988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "parameters = initialize_parameters_deep([3,2,1])\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 = [[ 0.93781623 -0.35319773 -0.3049401 ]\n",
            " [-0.61947872  0.49964333 -1.32879399]]\n",
            "b1 = [[0.]\n",
            " [0.]]\n",
            "W2 = [[ 1.23376823 -0.53825456]]\n",
            "b2 = [[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mrA2yIYmwor",
        "colab_type": "text"
      },
      "source": [
        "## Forward propagation \n",
        "\n",
        "### Linear Forward\n",
        "The linear forward module (vectorized over all the examples) computes the following equations:\n",
        "\n",
        "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\\tag{4}$$\n",
        "\n",
        "where $A^{[0]} = X$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wa7oM7x-kkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_forward(A, W, b):\n",
        "    \n",
        "    Z = W.dot(A) + b\n",
        "    \n",
        "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlPMK8VGans2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    \n",
        "    if activation == \"sigmoid\":\n",
        "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "    \n",
        "    elif activation == \"relu\":\n",
        "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "    \n",
        "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTIBBecFnXv9",
        "colab_type": "text"
      },
      "source": [
        "### L-Layer Model \n",
        "\n",
        "For even more convenience when implementing the $L$-layer Neural Net, we will need a function that replicates the previous one (`linear_activation_forward` with RELU) $L-1$ times, then follows that with one `linear_activation_forward` with SIGMOID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhHn3LV1ayr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_forward(X, parameters):\n",
        "\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2    # number of layers in the neural network\n",
        "    \n",
        "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
        "        caches.append(cache)\n",
        "    \n",
        "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
        "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "    \n",
        "    assert(AL.shape == (1,X.shape[1]))\n",
        "            \n",
        "    return AL, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIu5BmuSnnze",
        "colab_type": "text"
      },
      "source": [
        "## Cost function\n",
        "\n",
        "Now We will implement forward and backward propagation. We need to compute the cost, because we want to check if our model is actually learning.\n",
        "\n",
        "Compute the cross-entropy cost $J$, using the following formula: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjH-8zd6a-_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(AL, Y):\n",
        "\n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Compute loss from aL and y.\n",
        "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
        "    \n",
        "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy8AxKr7oKW7",
        "colab_type": "text"
      },
      "source": [
        "## Backward propagation \n",
        "\n",
        "Just like with forward propagation, you will implement helper functions for backpropagation. Remember that back propagation is used to calculate the gradient of the loss function with respect to the parameters. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TbjKl4NusIB",
        "colab_type": "text"
      },
      "source": [
        "[Chain Rule](https://drive.google.com/open?id=1k4PyaKRlMNFnE2GHmpXhzU1NQbbBTaJU)\n",
        "\n",
        "<caption><center> <br> *The purple blocks represent the forward propagation, and the red blocks represent the backward propagation.*  </center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7SOLn6ixpIU",
        "colab_type": "text"
      },
      "source": [
        "### Linear backward\n",
        "\n",
        "For layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).\n",
        "\n",
        "Suppose you have already calculated the derivative $dZ^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial Z^{[l]}}$. We want to get $(dW^{[l]}, db^{[l]} dA^{[l-1]})$.\n",
        "\n",
        "The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l]})$ are computed using the input $dZ^{[l]}$.Here are the formulas you need:\n",
        "$$ dW^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{8}$$\n",
        "$$ db^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{9}$$\n",
        "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \\tag{10}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGBK5USBbB6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    \n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
        "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
        "    dA_prev = np.dot(W.T,dZ)\n",
        "    \n",
        "    assert (dA_prev.shape == A_prev.shape)\n",
        "    assert (dW.shape == W.shape)\n",
        "    assert (db.shape == b.shape)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoSlkoVQyKPs",
        "colab_type": "text"
      },
      "source": [
        "### Linear-Activation backward\n",
        "\n",
        "Next, We create a function that merges the two helper functions: **`linear_backward`** and the backward step for the activation **`linear_activation_backward`**. \n",
        "\n",
        "To  implement `linear_activation_backward`, provided two backward functions:\n",
        "- **`sigmoid_backward`**: Implements the backward propagation for SIGMOID unit. You can call it as follows:\n",
        "\n",
        "```python\n",
        "dZ = sigmoid_backward(dA, activation_cache)\n",
        "```\n",
        "\n",
        "- **`relu_backward`**: Implements the backward propagation for RELU unit. You can call it as follows:\n",
        "\n",
        "```python\n",
        "dZ = relu_backward(dA, activation_cache)\n",
        "```\n",
        "\n",
        "If $g(.)$ is the activation function, \n",
        "`sigmoid_backward` and `relu_backward` compute $$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]}) \\tag{11}$$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXu5e6yOjESc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybvm5-L1oHJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        \n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    return dA_prev, dW, db\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fQK-gsHyuQB",
        "colab_type": "text"
      },
      "source": [
        "### L-Model Backward \n",
        "\n",
        "Now We implement the backward function for the whole network. We will iterate through all the hidden layers backward, starting from layer $L$. On each step, you will use the cached values for layer $l$ to backpropagate through layer $l$.\n",
        "\n",
        "#### Initializing backpropagation:\n",
        "\n",
        "To backpropagate through this network, we know that the output is, \n",
        "$A^{[L]} = \\sigma(Z^{[L]})$. Your code thus needs to compute `dAL` $= \\frac{\\partial \\mathcal{L}}{\\partial A^{[L]}}$.\n",
        "To do so, use this formula:\n",
        "```python\n",
        "dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL\n",
        "```\n",
        "$$grads[\"dW\" + str(l)] = dW^{[l]}\\tag{15} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra4mfbEQyd3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"sigmoid\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxMT90F-0ZHX",
        "colab_type": "text"
      },
      "source": [
        "### Update Parameters\n",
        "\n",
        "In this section We will update the parameters of the model, using gradient descent: \n",
        "\n",
        "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} \\tag{16}$$\n",
        "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{17}$$\n",
        "\n",
        "where $\\alpha$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYbubndR0QWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    # Update rule for each parameter. Use a for loop.\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
        "        \n",
        "    return parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhzk9Jt606cR",
        "colab_type": "text"
      },
      "source": [
        "## 5 - L-layer Neural Network\n",
        "\n",
        "\n",
        "```python\n",
        "def initialize_parameters_deep(layers_dims):\n",
        "    ...\n",
        "    return parameters \n",
        "def L_model_forward(X, parameters):\n",
        "    ...\n",
        "    return AL, caches\n",
        "def compute_cost(AL, Y):\n",
        "    ...\n",
        "    return cost\n",
        "def L_model_backward(AL, Y, caches):\n",
        "    ...\n",
        "    return grads\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    ...\n",
        "    return parameters\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDY82HSr0fOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### CONSTANTS ###\n",
        "layers_dims = [784,20, 7, 5,1] #  L-layer model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tptd44Io0_9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_layer_model(X_train, Y_train, layers_dims, learning_rate = 0.05, num_iterations = 3000, print_cost=False):\n",
        "\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization. (≈ 1 line of code)\n",
        "    parameters = initialize_parameters_deep(layers_dims)\n",
        "    \n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "        \n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        \n",
        "        AL, caches = L_model_forward(X_train, parameters)\n",
        "        \n",
        "        # Compute cost.\n",
        "        cost = compute_cost(AL, Y_train)\n",
        "    \n",
        "        # Backward propagation.\n",
        "        grads = L_model_backward(AL, Y_train, caches)\n",
        "        \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        # print(parameters)\n",
        "        # print(\"\\n\")\n",
        "                \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 50 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        if print_cost and i % 50 == 0:\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per tens)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-n6oihqXKfv",
        "colab_type": "code",
        "outputId": "8fdbefdc-4eba-4f20-9e48-91a392eb897e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        }
      },
      "source": [
        "parameters = L_layer_model((X_train),(Y_train), layers_dims, num_iterations = 1000, print_cost = True) # Sigmoid Inside"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.692425\n",
            "Cost after iteration 50: 0.686714\n",
            "Cost after iteration 100: 0.677010\n",
            "Cost after iteration 150: 0.655827\n",
            "Cost after iteration 200: 0.609800\n",
            "Cost after iteration 250: 0.526424\n",
            "Cost after iteration 300: 0.431368\n",
            "Cost after iteration 350: 0.360715\n",
            "Cost after iteration 400: 0.310368\n",
            "Cost after iteration 450: 0.271352\n",
            "Cost after iteration 500: 0.238207\n",
            "Cost after iteration 550: 0.208913\n",
            "Cost after iteration 600: 0.182844\n",
            "Cost after iteration 650: 0.159716\n",
            "Cost after iteration 700: 0.139383\n",
            "Cost after iteration 750: 0.121865\n",
            "Cost after iteration 800: 0.106888\n",
            "Cost after iteration 850: 0.094225\n",
            "Cost after iteration 900: 0.083518\n",
            "Cost after iteration 950: 0.074430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEWCAYAAAAAZd6JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMXrzLuxX1es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  L-layer neural network.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    parameters -- parameters of the trained model\n",
        "    \n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1,m))\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "    \n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "    \n",
        "    #print results\n",
        "    #print (\"predictions: \" + str(p))\n",
        "    #print (\"true labels: \" + str(y))\n",
        "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "        \n",
        "    return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R5dEaPxX_Ud",
        "colab_type": "code",
        "outputId": "d690e721-bbe6-4501-e2ae-f2d5eacada74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(X_train, Y_train, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9867703494243584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP-eJSmuYF1F",
        "colab_type": "code",
        "outputId": "873e1194-d942-4115-9842-2f501e5eff2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(X_test, Y_test, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9874948749487495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDEzu2rH1Eke",
        "colab_type": "code",
        "outputId": "2f1b680f-938c-4d92-e4bd-cd5c18eaeb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        }
      },
      "source": [
        "parameters = L_layer_model((X_train),(Y_train), layers_dims, num_iterations = 1000, print_cost = True) # Relu Inside"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.692425\n",
            "Cost after iteration 50: 0.649152\n",
            "Cost after iteration 100: 0.297155\n",
            "Cost after iteration 150: 0.191365\n",
            "Cost after iteration 200: 0.133559\n",
            "Cost after iteration 250: 0.097384\n",
            "Cost after iteration 300: 0.073499\n",
            "Cost after iteration 350: 0.057208\n",
            "Cost after iteration 400: 0.045781\n",
            "Cost after iteration 450: 0.037550\n",
            "Cost after iteration 500: 0.031469\n",
            "Cost after iteration 550: 0.026859\n",
            "Cost after iteration 600: 0.023286\n",
            "Cost after iteration 650: 0.020462\n",
            "Cost after iteration 700: 0.018191\n",
            "Cost after iteration 750: 0.016342\n",
            "Cost after iteration 800: 0.014808\n",
            "Cost after iteration 850: 0.013522\n",
            "Cost after iteration 900: 0.012430\n",
            "Cost after iteration 950: 0.011492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEWCAYAAAAAZd6JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3xU9Z3/8dc7k3sgIYFwC+GixQve\nUOOt1q671a5YC1atYm9qd5fa1tqtu7/+7LZru27d1Xbbbu26a6311q1StdWi0rW2Wy+1KgQFFBBF\nRAgiRIJACLlM8tk/zgkOcZJMQk5mJvN5Ph7zmDPnfGfmM2fIm3PmnPP9ysxwzjnXu7x0F+Ccc5nO\ng9I55/rhQemcc/3woHTOuX54UDrnXD88KJ1zrh8elG7YSTpN0tp01+Fcqjwoc4ykDZLOSGcNZvaU\nmR2azhq6STpdUsMwvdeHJL0sqUXSHyRN66Pt9LBNS/icMxKWXSqpU1Jzwu304fgMucqD0g05SbF0\n1wCgQEb8G5c0DvgV8I9AFVAP/KKPp9wDvACMBb4O3C+pOmH5M2Y2KuH2eDSVO/CgdCFJeZKulvSa\npO2S7pVUlbD8PklvSdop6UlJRyQsu0PSf0laLGkP8OfhluvfS1oZPucXkorD9vttxfXVNlz+VUlb\nJL0p6a8lmaT39fI5Hpd0naSngRbgIEmXSVojabek9ZI+F7YtA34DTE7YMpvc37oYpPOAVWZ2n5m1\nAt8CjpF0WJLPcAhwHPBNM9trZr8EXgTOP8Aa3CB5ULpuXwLOBf4MmAzsAG5KWP4bYCYwHnge+HmP\n538CuA4YDfwxnHchcBYwAzgauLSP90/aVtJZwFXAGcD7gNNT+CyfBhaEtbwBbAPOAcqBy4AfSDrO\nzPYAc4A3E7bM3kxhXewjaaqkd/q4fSJsegSwovt54Xu/Fs7v6QhgvZntTpi3okfbYyW9LekVSf8o\nKT+F9eIGyVeu63Y5cIWZNQBI+hawUdKnzSxuZrd1NwyX7ZBUYWY7w9m/NrOnw+lWSQA3hsGDpIeA\n2X28f29tLwRuN7NVCe/9yX4+yx3d7UOPJEw/Iem3wGkEgZ9Mn+sisaGZbQTG9FMPwCigsce8nQRh\nnqztziRta8LpJ4EjCf4TOIJgFz4O/GsKdbhB8C1K120a8ED3lhCwBugEJkiKSbo+3BXdBWwInzMu\n4fmbkrzmWwnTLQQB0Jve2k7u8drJ3qen/dpImiPpWUlN4Wc7m/1r76nXdZHCe/emmWCLNlE5sHug\nbc1svZm9bmZdZvYicC1wwQHU5vrhQem6bQLmmNmYhFuxmW0m2K2eR7D7WwFMD5+jhOdH1Q3VFmBK\nwuPaFJ6zrxZJRcAvgX8DJpjZGGAx79aerO6+1sV+wl3v5j5u3Vu/q4BjEp5XBhwczu9pFcFvq4lb\nm8f00rb7M6iXZW4IeFDmpgJJxQm3fOBm4DqFp6xIqpY0L2w/GmgDtgOlwL8MY633ApdJOlxSKcFR\n44EoBIoIdnvjkuYAH05YvhUYK6kiYV5f62I/Zraxx9Hnnrfu33IfAI6UdH54oOoaYKWZvZzkNV8B\nlgPfDL+fjxH8bvvLsJ45kiaE04eF6+TXA1wvbgA8KHPTYmBvwu1bwA+BRcBvJe0GngVOCtvfRfB7\n2GZgdbhsWJjZb4AbgT8A6xLeuy3F5+8GriQI3B0EW8eLEpa/THAqzvpwV3syfa+LwX6ORoKj1teF\ndZwEzO9eLulmSTcnPGU+UBe2vR64IHwNgA8BK8MzDBYTnHY0nP955Rx5x70um0g6HHgJKOp5YMW5\nqPgWpct4kj4mqUhSJXAD8JCHpBtOHpQuG3yO4FzI1wiOPn8+veW4XOO73s451w/fonTOuX5k3ZU5\n48aNs+nTp6e7DOfcCLNs2bK3zaw62bKsC8rp06dTX1+f7jKccyOMpDd6W+a73s451w8PSuec64cH\npXPO9SPSoJR0lqS1ktZJujrJ8h9IWh7eXgl7anHOuYwS2cEcBcMB3AScCTQASyUtMrPV3W3M7CsJ\n7b8EHBtVPc45N1hRblGeCKwL+85rBxYSdNXVm4sJOidwzrmMEmVQ1rB/B6oNvNtD837C7qxmAP/b\ny/IFkuol1Tc29uwk2jnnopUpB3PmA/ebWWeyhWZ2i5nVmVlddXXS80GTMjO+/9grvLI1WSfSzjmX\nmiiDcjP790Y9JZyXzHwi2O1ubG7jniUbufDHz7Bikx8ncs4NTpRBuRSYKWmGpEKCMFzUs1HYQ3Ml\n8MxQFzB+dDH3X34Ko4ry+eStz/Hs+u1D/RbOuRwQWVCG/QVeATxKMDjTvWa2StK1kuYmNJ0PLLSI\nujGaNraM+y4/hQnlRVxy2xL+8PK2KN7GOTeCZV03a3V1dTaYa723N7dxye1LeHnLbn5w0Ww+eszk\nCKpzzmUrScvMrC7Zskw5mBO5saOKuPtvTubYqWO4cuELLFyyMd0lOeeyRM4EJUB5cQF3ffYkPjiz\nmqt/9SK3PrU+3SU557JATgUlQElhjJ98po6zj5rItx9Zw/cfe4Vs+/nBOTe8sq4/yqFQmJ/HjfOP\npazwRW78/avsbu3gHz8yi7w8H0PeOfdeORmUAPmxPG44/2hGFedz+9MbaG6Nc/35RxPzsHTO9ZCz\nQQmQlyeuOWcWo4sLuPH3r7KnPc6/X3Qshfk594uEc64POR2UAJK46sxDKC/O59uPrGFPWz03f+p4\nSgpj6S7NOZchfNMp9NenHcQN5x/Fk682csltS9jV2pHukpxzGcKDMsFFJ0zlRxcfy/Mbd3DlPS+k\nuxznXIbI+V3vns45ejJLX2/ivmUNmBmSH9xxLtf5FmUS08eV0dLeyfY97ekuxTmXATwok6itLAVg\nU1NLmitxzmUCD8okpo4NgnKjB6VzDg/KpKZUlgDQsGNvmitxzmUCD8okSgvzGTeqyHe9nXOAB2Wv\naqtKfNfbOQd4UPaqtrKUTTs8KJ1zHpS9mlpVypvvtBLv7Ep3Kc65NPOg7EVtVQmdXcaWna3pLsU5\nl2YelL2orfJThJxzgUiDUtJZktZKWifp6l7aXChptaRVku6Osp6B8JPOnXPdIrvWW1IMuAk4E2gA\nlkpaZGarE9rMBL4GnGpmOySNj6qegZpUUUx+nnyL0jkX6RblicA6M1tvZu3AQmBejzZ/A9xkZjsA\nzCxjBt3Oj+UxeUwJm/ykc+dyXpRBWQNsSnjcEM5LdAhwiKSnJT0r6axkLyRpgaR6SfWNjY0Rlfte\ntVUlvuvtnEv7wZx8YCZwOnAx8BNJY3o2MrNbzKzOzOqqq6uHrbipVaUelM65SINyM1Cb8HhKOC9R\nA7DIzDrM7HXgFYLgzAhTKkvZvqedPW3xdJfinEujKINyKTBT0gxJhcB8YFGPNg8SbE0iaRzBrvj6\nCGsakKnhKUJ+hY5zuS2yoDSzOHAF8CiwBrjXzFZJulbS3LDZo8B2SauBPwD/z8y2R1XTQHWfS7mp\nyQ/oOJfLIh0KwswWA4t7zLsmYdqAq8JbxpnqJ50750j/wZyMVllaQFlhzA/oOJfjPCj7IInaqlIa\n/DdK53KaB2U/aqtKfdfbuRznQdmP2spSNjXtJfg51TmXizwo+zG1qoS9HZ283exD1zqXqzwo+1Hr\n51I6l/M8KPux76Rz/53SuZzlQdmPKd4vpXM5z4OyHyWFMapHF/nVOc7lMA/KFNRW+tC1zuUyD8oU\n1Fb50LXO5TIPyhQEQ9fupcOHrnUuJ3lQpqC2spQugy3v+NC1zuUiD8oU+NC1zuU2D8oU1FaVAH7S\nuXO5yoMyBZMqSsjPk59L6VyO8qBMQSxP1PgpQs7lLA/KFE2tKvUxvp3LUR6UKZpS6UPXOperPChT\nVFtVQtOedpp96Frnck6kQSnpLElrJa2TdHWS5ZdKapS0PLz9dZT1HAjvRci53BVZUEqKATcBc4BZ\nwMWSZiVp+gszmx3ebo2qngNV670IOZezotyiPBFYZ2brzawdWAjMi/D9IuVD1zqXu6IMyhpgU8Lj\nhnBeT+dLWinpfkm1yV5I0gJJ9ZLqGxsbo6i1X2NKCxhVlE+DH/l2Luek+2DOQ8B0MzsaeAy4M1kj\nM7vFzOrMrK66unpYC+zWPXSt73o7l3uiDMrNQOIW4pRw3j5mtt3M2sKHtwLHR1jPAfN+KZ3LTVEG\n5VJgpqQZkgqB+cCixAaSJiU8nAusibCeAzY17JfSh651LrfkR/XCZhaXdAXwKBADbjOzVZKuBerN\nbBFwpaS5QBxoAi6Nqp6hUFtVSmtHF43NbYwfXZzucpxzwySyoAQws8XA4h7zrkmY/hrwtShrGEr7\nehFq2utB6VwOSffBnKziJ507l5s8KAfAh651Ljd5UA5AcUGM8aOLvANf53KMB+UA1VaV+ilCzuUY\nD8oBmlpVyqYmvzrHuVziQTlAtZUlbNnpQ9c6l0s8KAdoSlUwdO2b7/hWpXO5woNygLwXIedyjwfl\nANXuO5fStyidyxUelAM0sbyYgpj8FCHncogH5QDF8kTNGO9FyLlc4kE5CLVVpTR4UDqXMzwoB8FP\nOncut3hQDsLUqlJ2tHSwu7Uj3aU454aBB+UgvDsiox/5di4XeFAOwr5+Kf3It3M5wYNyELxfSudy\niwflIFSUFDC6KN+D0rkc4UE5CPuGrvUxvp3LCR6Ug1Rb5SedO5crIg1KSWdJWitpnaSr+2h3viST\nVBdlPUMp6JfSh651LhdEFpSSYsBNwBxgFnCxpFlJ2o0Gvgw8F1UtUaitKqUt3kXj7rZ0l+Kci1iU\nW5QnAuvMbL2ZtQMLgXlJ2v0zcAPQGmEtQ27fuZR+ipBzI16UQVkDbEp43BDO20fScUCtmT3S1wtJ\nWiCpXlJ9Y2Pj0Fc6CLXeL6VzOSNtB3Mk5QHfB/6uv7ZmdouZ1ZlZXXV1dfTFpWBKZXjSuV+d49yI\nF2VQbgZqEx5PCed1Gw0cCTwuaQNwMrAoWw7oFBfEmFBe5OdSOpcDogzKpcBMSTMkFQLzgUXdC81s\np5mNM7PpZjYdeBaYa2b1EdY0pGorvRch53JBZEFpZnHgCuBRYA1wr5mtknStpLlRve9wmlpVSoOf\ndO7ciJcf5Yub2WJgcY951/TS9vQoa4nClKpSHli+mfZ4F4X5fu6+cyNVSn/dkj6eyrxcM7WqFPOh\na50b8VLdDPpaivNySm145Nt/p3RuZOtz11vSHOBsoEbSjQmLyoF4lIVlg31D1/pJ586NaP39Rvkm\nUA/MBZYlzN8NfCWqorLFhPJiCmN5fi6lcyNcn0FpZiuAFZLuNrMOAEmVBFfT7BiOAjNZLE/UVJb4\nuZTOjXCp/kb5mKRySVXA88BPJP0gwrqyRtAvpQelcyNZqkFZYWa7gPOAu8zsJOBD0ZWVPWorvV9K\n50a6VIMyX9Ik4ELg4QjryTpTq0p5p6WDXT50rXMjVqpBeS3BFTavmdlSSQcBr0ZXVvao9YHGnBvx\nUgpKM7vPzI42s8+Hj9eb2fnRlpYdfIxv50a+VK/MmSLpAUnbwtsvJU2Jurhs0D10bYMf0HFuxEp1\n1/t2gp5/Joe3h8J5Oa+itIDRxfl+QMe5ESzVoKw2s9vNLB7e7gAyowfdDNA90JhzbmRKNSi3S/qU\npFh4+xSwPcrCson3S+ncyJZqUH6W4NSgt4AtwAXApRHVlHWmjg36pezq8qFrnRuJBnJ60CVmVm1m\n4wmC85+iKyu71FaWBEPXNvvQtc6NRKkG5dGJ13abWRNwbDQlZR8/l9K5kS3VoMwLO8MAILzmO9Le\n0bOJD13r3MiWath9D3hG0n3h448D10VTUvapGeND1zo3kqUUlGZ2l6R64C/CWeeZ2eroysouxQUx\nJpYXey9Czo1QKe8+h8E4oHCUdBbwQyAG3Gpm1/dYfjnwRaATaAYWZGsA11Z5L0LOjVSRDR0oKQbc\nBMwBZgEXS5rVo9ndZnaUmc0GvgN8P6p6olZbVUqDB6VzI1KUY6yeCKwLO9BoBxYC8xIbhH1cdisD\nsvZExNrKUrbsaqUt3pnuUpxzQyzKoKwBNiU8bgjn7UfSFyW9RrBFeWWyF5K0QFK9pPrGxsZIij1Q\n3UPXNuzwAzrOjTRRBmVKzOwmMzsY+P/AN3ppc4uZ1ZlZXXV1Zl5ifty04Oyph1dsSXMlzrmhFmVQ\nbgZqEx5PCef1ZiFwboT1RGrGuDJOP7Sa/37uDd/9dm6EiTIolwIzJc2QVAjMJ+iqbR9JMxMefoQs\n7zX9slNn0Li7jUdW+lalcyNJZEFpZnHgCoIhJNYA95rZKknXSpobNrtC0ipJy4GrgEuiqmc4fHDm\nON43fhS3P70Bs6w9LuWc6yHSyxDNbDGwuMe8axKmvxzl+w83SVz6/ul848GXWPbGDuqmV6W7JOfc\nEEj7wZyR5rzjaigvzue2p19PdynOuSHiQTnESgvzufjEqTy6aiub3/FThZwbCTwoI/CZ908H4K5n\nNqSzDOfcEPGgjEDNmBL+8ogJLFyyiZb2eLrLcc4dIA/KiFx26gx27u3gV8/3deqocy4beFBGpG5a\nJUfVVHDHn/xUIeeynQdlRCRx2anTWbetmadefTvd5TjnDoAHZYQ+cvQkxo0q8lOFnMtyHpQRKsqP\n8amTp/L42kZea2xOdznOuUHyoIzYJ0+aRmEsjzv/tCHdpTjnBsmDMmLVo4v46DGTuX9ZAzv3dqS7\nHOfcIHhQDoPLTp1OS3sn9y7d1H9j51zG8aAcBkfWVHDijCrufGYDnV1+qpBz2caDcph89tTpNOzY\ny2Ort6a7FOfcAHlQDpMzZ02kZkyJnyrkXBbyoBwmsbygr8olrzex6s2d6S7HOTcAHpTD6MITaikt\njHH70xvSXYpzbgA8KIdRRUkB5x83hUXL36Rxd1u6y3HOpciDcphdeup02ju7uPu5jekuxTmXIg/K\nYXZw9Sgf1ta5LBNpUEo6S9JaSeskXZ1k+VWSVktaKen3kqZFWU+m8GFtncsukQWlpBhwEzAHmAVc\nLGlWj2YvAHVmdjRwP/CdqOrJJB+cOY6Dq8t8WFvnskSUW5QnAuvMbL2ZtQMLgXmJDczsD2bWEj58\nFpgSYT0ZI+ircgYvbt7Jsjd2pLsc51w/ogzKGiDx4uaGcF5v/gr4TbIFkhZIqpdU39jYOIQlpo8P\na+tc9siIgzmSPgXUAd9NttzMbjGzOjOrq66uHt7iIuLD2jqXPaIMys1AbcLjKeG8/Ug6A/g6MNfM\ncurkwu5hbX/w2CvpLcQ516cog3IpMFPSDEmFwHxgUWIDSccCPyYIyW0R1pKRasaU8Pk/O5j7lzX4\neZXOZbDIgtLM4sAVwKPAGuBeM1sl6VpJc8Nm3wVGAfdJWi5pUS8vN2J95cxD+LNDqvnmopf8wI5z\nGUrZdnpKXV2d1dfXp7uMIbWzpYOP/scfae3o5OEvfYDx5cXpLsm5nCNpmZnVJVuWEQdzcl1FaQE/\n/vTx7G6N84WfP097vCvdJTnnEnhQZojDJ5VzwwVHU//GDv754dXpLsc5lyA/3QW4d809ZjIvbd7J\nLU+u56gpFVxYV9v/k5xzkfMtygzz1b88lFPfN5ZvPPgSKza9k+5ynHN4UGac/FgeP7r4OKpHFXH5\nfy/j7eacOrXUuYzkQZmBqsoK+fGnj6dpTztf/PnzdHT6wR3n0smDMkMdWVPBv553FM+93sS/Ln45\n3eU4l9P8YE4GO++4Kaxs2MltT7/OUVPK+dixOdG5knMZx7coM9zXP3I4J86o4mu/epGXNvvojc6l\ngwdlhiuI5XHTJ45jTEkhn/vZMpr2tKe7JOdyjgdlFqgeXcTNnz6ext1tXHnPC8T94I5zw8qDMkvM\nrh3Dt889kj+ue5vv/nZtustxLqd4UGaRC0+o5ZMnTeXHT6znoRVvprsc53KGB2WW+eZHj+D4aZVc\nde9y7nrGBydzbjh4UGaZwvw8brv0BE6bWc01v17F3923gtYOHx/cuSh5UGahipICbv1MHV854xAe\neGEz5/3nn9jU1NL/E51zg+JBmaXy8sSXz5jJbZecQMOOFs750R95fG3Ojabh3LDwoMxyf37YeB76\n0geYVFHMZXcs5Ue/f5WuLv/d0rmh5EE5AkwbW8YDXziVecdM5nuPvcKCny1jV2tHustybsTwoBwh\nSgpj/OCi2Xzro7N4fO025v3H06x9a3e6y3JuRIg0KCWdJWmtpHWSrk6y/IOSnpcUl3RBlLXkAklc\neuoM7llwMs1tcc696Wk/39K5IRBZUEqKATcBc4BZwMWSZvVothG4FLg7qjpy0QnTq3jkSx/giMnl\nfOmeF/j2w6v9skfnDkCUW5QnAuvMbL2ZtQMLgXmJDcxsg5mtBPyveIiNLy/m7r85mUtOmcatf3yd\nT/30Oe8t3blBijIoa4BNCY8bwnkDJmmBpHpJ9Y2NjUNSXC4ozM/jn+YdyfcvPIYXNr7DOTf+kV8v\n3+xHxZ0boKw4mGNmt5hZnZnVVVdXp7ucrHPecVP41Rfez5jSAr68cDln3/gUv131ll/+6FyKogzK\nzUDieKtTwnkuDY6YXMHiK0/jh/Nn0xbvYsHPlnHuTU/z5CuNHpjO9SPKoFwKzJQ0Q1IhMB9YFOH7\nuX7k5Yl5s2t47Csf5Ibzj+Lt5nY+c9sS5t/yLPUbmtJdnnMZS1FuTUg6G/h3IAbcZmbXSboWqDez\nRZJOAB4AKoFW4C0zO6Kv16yrq7P6+vrIas4lbfFOFi7ZxI/+dx1vN7dx+qHV/P2HD+XImop0l+bc\nsJO0zMzqki7Ltt0uD8qht7e9kzuf2cDNT7zGOy0dzDlyIledeQgzJ4xOd2nODRsPSpeSXa0d/PSp\n1/npH19nT3ucj82u4ctnzGTa2LJ0l+Zc5Dwo3YA07Wnnx0+8xp3PbCDeacw5ahLnzp7MaTOrKczP\nihMlnBswD0o3KNt2tfJfT7zGgy9sZkdLB5WlBZx91CTOPbaG46dWkpendJfo3JDxoHQHpKOzi6de\nbeTBF97ksdVb2dvRSc2YEubOnsy5s2s4dKL/lumynwelGzJ72uI8tnorDy7fzFOvvk1nl3HYxNHM\nm13D3NmTqRlTku4SnRsUD0oXibeb21j84hYefGEzz298B4ATZ1Qxb/Zkzj5yEpVlhWmu0LnUeVC6\nyG3c3sKvl2/mweWbea1xDxIcPrGckw8ay8kHVXHijCrGlHpwuszlQemGjZmx6s1d/G7NVp5b38Tz\nG3fQFu9CgsMmlnPyQVWcNGMsJ82o8i1Ol1H6Csr84S7GjWySOLKmYt/VPW3xTlZs2smz67fz3Ovb\nuWfJRm5/egMAh00cnbDFOZYqD06XoXyL0g2r9ngXKxveCYOzifoNO9gbjkt+yIRRHFlTwWETR3PY\nxHIOmzSa6lFFSH4akoue73q7jNUe7+LFze/w7Pomlm5o4uUtu3lrV+u+5WPLCjk0ITgPn1jOzAmj\nKC6IpbFqNxL5rrfLWIX5eRw/rYrjp1Xtm7djTzsvv7Wbl9/axctbgvu7l7xBa0fQEX6eYPq4Mg6f\nWM5hE0dz8PhRTK0qpbaqlIqSgnR9FDeCeVC6jFNZVsgpB4/llIPH7pvX2WVsbGrh5S27WPPWbl7e\nsosXN+/kkRe37Pfc8uJ8po4t3RecUxNuk8eUUBDzSzDdwHlQuqwQyxMzxpUxY1wZc46atG9+c1uc\nN7bvYVNTC5ua9rKxqSUM1N38bvU22hMGVcsTTKooYWpVKVMqS5hQXsyE8iLGlxczfnQRE8qLqR5d\n5GHq3sOD0mW1UUX5HDG5giMmv7cPzc4uY+uu1n3h2RDeb2xq4YlXGnm7uY1kwweNLStMCM8gQMeP\nDgJ1bFkhlWWFVJUWUlFS4Ne75wgPSjdixfLE5DElTB5TwskHjX3P8s4uY3tzG9t2t7F1Vytbd7Wx\nbXd4v6uVbbvbWLNlV6+BmicYU1pIZWkBVWWFVJYWBvdhkFaWFVJVVkBFSQHlxQWUlxQwujifkoKY\nH8nPMh6ULmfF8hRsOZYX99mre3egbt3VRlNLOzv2tNO0p50dLeFtTwdNe9rZ2NTC8k3vsKOlnY7O\n3s8myc/TvtAMAjSf0UXBfXlxAaOLg2WjivIpK8qntCgWTBfmU1YUo6woWFaUn+eBO0w8KJ3rR2Kg\npsLMaG6Ls2NPB9v3tLGrNc6uvR3sau1gd9LpONt2NQePWztoae9Mua7SwiBEu+9LCmOUFMTC+3xK\nCvOCxwUxSgrzKSnIo6QwRnFBjNLCYOu2uCCP4oIYRfnv3heF8wtjHsbgQenckJMUbhUWMHVs6YCf\n39HZRXNrnOa2OC3tnTS3xdnTFqelPU5zW2d4H8zb09YZ3IfLWts7ebu5nb0dnext79zvfnCfhSA4\n84PgTLwvzA+CtCgM1ML84Nbdvnt59/x907E8CvJFQax7OryP5VEQC+fn7/+4IJZHfkwU5AX3+Xka\n1gD3oHQuwxTE8qgMf+scKmZGa0dXEJzd4dkehG5bvIvWjs6k920dnbR233d00RZ/9769s4u2ji72\ntMdpj3fRHu8KnhPvoj1c3h7vSvr77lAoiIn8MDgLY90B+m643nbpCdRWDfw/qmQiDUpJZwE/JBiF\n8VYzu77H8iLgLuB4YDtwkZltiLIm53KRpGB3vHD4r2iKd3btC9WOcLqj04LpeDBv3+POLjri+z9u\nj3cR7+wi3mV0dBrxzi46usL78Lnxri7inbZvuqOzi6KCoTvNK7KglBQDbgLOBBqApZIWmdnqhGZ/\nBewws/dJmg/cAFwUVU3OueGXH8sjP5ZHNveyF+WZtScC68xsvZm1AwuBeT3azAPuDKfvBz4k/+XY\nOZdhogzKGmBTwuOGcF7SNmYWB3YC7znhTdICSfWS6hsbGyMq1znnksuKa7XM7BYzqzOzuurq6nSX\n45zLMVEG5WagNuHxlHBe0jaS8oEKgoM6zjmXMaIMyqXATEkzJBUC84FFPdosAi4Jpy8A/teyrYNM\n59yIF9lRbzOLS7oCeJTg9KDbzGyVpGuBejNbBPwU+JmkdUATQZg651xGifQ8SjNbDCzuMe+ahOlW\n4ONR1uCccwcqKw7mOOdcOmXdmDmSGoE3Bvi0ccDbEZSTbTVAZtThNbwrE+rwGgLTzCzpaTVZF5SD\nIam+t0GDcqmGTKnDa8isOsbPnLkAAAhUSURBVLyG/vmut3PO9cOD0jnn+pErQXlLugsgM2qAzKjD\na3hXJtThNfQjJ36jdM65A5ErW5TOOTdoHpTOOdePERWUks6StFbSOklXJ1leJOkX4fLnJE0f4vev\nlfQHSaslrZL05SRtTpe0U9Ly8HZNstc6wDo2SHoxfP36JMsl6cZwPayUdFwENRya8BmXS9ol6W97\ntBnydSHpNknbJL2UMK9K0mOSXg3vK3t57iVhm1clXZKszQHW8V1JL4fr/AFJY3p5bp/f3wHW8C1J\nmxPW+dm9PLfPv6UDrOEXCe+/QdLyXp47JOthSJjZiLgRXE/+GnAQUAisAGb1aPMF4OZwej7wiyGu\nYRJwXDg9GnglSQ2nAw9HvC42AOP6WH428BtAwMnAc8Pw3bxFcEJvpOsC+CBwHPBSwrzvAFeH01cD\nNyR5XhWwPryvDKcrh7iODwP54fQNyepI5fs7wBq+Bfx9Ct9Xn39LB1JDj+XfA66Jcj0MxW0kbVGm\nvUd1M9tiZs+H07uBNby3s+JMMA+4ywLPAmMkTYrw/T4EvGZmA72iasDM7EmCDlYSJX7vdwLnJnnq\nXwKPmVmTme0AHgPOGso6zOy3FnRQDfAsQdeDkellXaQilb+lA64h/Nu7ELhnMK89nEZSUA5Zj+pD\nIdytPxZ4LsniUyStkPQbSUdE8PYG/FbSMkkLkixPZV0Npfn0/scQ9boAmGBmW8Lpt4AJSdoM9zr5\nLMFWfTL9fX8H6opw9/+2Xn6GGK51cRqw1cxe7WV51OshZSMpKDOGpFHAL4G/NbNdPRY/T7ALegzw\nI+DBCEr4gJkdB8wBvijpgxG8R0rCvkjnAvclWTwc62I/FuzTpfWcOElfB+LAz3tpEuX391/AwcBs\nYAvBrm+6XEzfW5MZ8+94JAVlRvSoLqmAICR/bma/6rnczHaZWXM4vRgokDRuKGsws83h/TbgAYJd\nqUSprKuhMgd43sy2Jqkz8nUR2tr900J4vy1Jm2FZJ5IuBc4BPhmG9nuk8P0NmpltNbNOM+sCftLL\na0e+LsK/v/OAX/RRa2TrYaBGUlCmvUf18DeXnwJrzOz7vbSZ2P27qKQTCb6DIQtrSWWSRndPExxA\neKlHs0XAZ8Kj3ycDOxN2TYdar1sNUa+LBInf+yXAr5O0eRT4sKTKcHf0w+G8IaNgnPuvAnPNrKWX\nNql8fwdSQ+Jv0R/r5bVT+Vs6UGcAL5tZQy91RroeBizdR5OG8kZwNPcVgiN2Xw/nXUvwDxOgmGAX\ncB2wBDhoiN//AwS7dSuB5eHtbOBy4PKwzRXAKoIjic8C7x/iGg4KX3tF+D7d6yGxBhGMuf4a8CJQ\nF9H3UUYQfBUJ8yJdFwShvAXoIPht7a8Ifof+PfAq8DugKmxbB9ya8NzPhv821gGXRVDHOoLf/rr/\nbXSfgTEZWNzX9zeENfws/M5XEoTfpJ419Pa3NFQ1hPPv6P53kNA2kvUwFDe/hNE55/oxkna9nXMu\nEh6UzjnXDw9K55zrhwelc871w4PSOef64UHpeiXpT+H9dEmfGOLX/odk7xUVSecORe9Evbz2P/Tf\nasCveZSkO4b6dd3g+OlBrl+STifoceacATwn397tACLZ8mYzGzUU9aVYz58Izqc9oCFRk32uqD6L\npN8BnzWzjUP92m5gfIvS9UpSczh5PXBa2C/gVyTFwr4Vl4adK3wubH+6pKckLQJWh/MeDDs1WNXd\nsYGk64GS8PV+nvhe4dVC35X0UtgX4UUJr/24pPsV9On484Sreq5X0AfoSkn/luRzHAK0dYekpDsk\n3SypXtIrks4J56f8uRJeO9ln+ZSkJeG8H0uKdX9GSdcp6ATkWUkTwvkfDz/vCklPJrz8QwRXxbh0\nS+fZ7n7L7BvQHN6fTkK/kcAC4BvhdBFQD8wI2+0BZiS07b4KpoTgErSxia+d5L3OJ+jiLEbQy89G\ngn4+Tyfo7WkKwX/wzxBcCTUWWMu7e0djknyOy4DvJTy+A/if8HVmElwxUjyQz5Ws9nD6cIKAKwgf\n/yfwmXDagI+G099JeK8XgZqe9QOnAg+l+9+B34z8VAPVuQQfBo6WdEH4uIIgcNqBJWb2ekLbKyV9\nLJyuDdv1dT33B4B7zKyToDOLJ4ATgF3hazcAKOgVezrBpY+twE8lPQw8nOQ1JwGNPebda0HHEK9K\nWg8cNsDP1ZsPAccDS8MN3hLe7YSjPaG+ZcCZ4fTTwB2S7gUSO1LZRnBZn0szD0o3GAK+ZGb7dRoR\n/pa5p8fjM4BTzKxF0uMEW26D1ZYw3UnQW3g87FDjQwQdnVwB/EWP5+0lCL1EPX+cN1L8XP0QcKeZ\nfS3Jsg4LNxW76wcws8slnQR8BFgm6Xgz206wrvam+L4uQv4bpUvFboKhLbo9CnxeQZdySDok7OGl\npwpgRxiShxEMO9Gto/v5PTwFXBT+XlhNMJTAkt4KU9D3Z4UF3bR9BTgmSbM1wPt6zPu4pDxJBxN0\nwLB2AJ+rp8TP8nvgAknjw9eokjStrydLOtjMnjOzawi2fLu7ODuEdPaY4/bxLUqXipVAp6QVBL/v\n/ZBgt/f58IBKI8mHV/gf4HJJawiC6NmEZbcAKyU9b2afTJj/AHAKQa8xBnzVzN4KgzaZ0cCvJRUT\nbM1dlaTNk8D3JClhi24jQQCXE/Ri0yrp1hQ/V0/7fRZJ3yDomTuPoNecLwJ9DYPxXUkzw/p/H352\ngD8HHknh/V3E/PQglxMk/ZDgwMjvwvMTHzaz+9NcVq8kFQFPEPTy3etpVm54+K63yxX/ApSmu4gB\nmEowcqSHZAbwLUrnnOuHb1E651w/PCidc64fHpTOOdcPD0rnnOuHB6VzzvXj/wAoBK/nUaH/HAAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag80uBpz1QiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  L-layer neural network.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    parameters -- parameters of the trained model\n",
        "    \n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1,m))\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "    \n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "    \n",
        "    #print results\n",
        "    #print (\"predictions: \" + str(p))\n",
        "    #print (\"true labels: \" + str(y))\n",
        "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "        \n",
        "    return p\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0VNVZOp1BLZ",
        "colab_type": "code",
        "outputId": "368b1437-2793-438f-c97e-3cf26f64bd7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(X_train, Y_train, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9984851545142392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kspXv5HM1JzR",
        "colab_type": "code",
        "outputId": "ad7612a8-f4c5-4d67-b7df-c8dc594ab32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(X_test, Y_test, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9993849938499385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGpKvZHsvtqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}